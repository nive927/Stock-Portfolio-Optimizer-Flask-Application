{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right;\" width=\"120\" src=\"../Images/supplier-logo.png\">\n",
    "<img style=\"float: left; margin-top: 0\" width=\"80\" src=\"../Images/client-logo.png\">\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series\n",
    "- Basics\n",
    "- slicing into timezones\n",
    "- ranges and frequencies\n",
    "- resampling\n",
    "- shift and tshift\n",
    "- interpolation\n",
    "- moving windows - rolling and expanding\n",
    "- aggregating data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# format for floats\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Basics\n",
    "\n",
    "- Always pay attention to how pandas builds indexes that are timeseries\n",
    "- Especially true when loading in Data from multiple Data sources\n",
    "- Once the timeseries is indexed correctly (ascending or descending) accessing rows and columns is fairly flexible\n",
    "- Special care **MUST** be taken when loading in data from Excel Spreadsheets and CSV files\n",
    "- Also be careful with date formats\n",
    "- e.g. 2010-03-01 and 2010-01-03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL = pd.read_excel('../Data/market_data.xls', sheet_name='GOOGL', index_col='Date', parse_dates=True)\n",
    "\n",
    "df_GOOGL.tail()\n",
    "df_GOOGL['2010']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Ranges\n",
    "\n",
    "Note that sometimes when slicing by date range, you can be caught out by the order of the dates in your index.\n",
    "\n",
    "i.e. is the first row the earliest date OR the latest date?\n",
    "\n",
    "It's good practice when dealing with dates as your index, to explicitly sort the index before filtering by a slice of dates. This avoids any surprises.\n",
    "\n",
    "The slice you filter by must match the sorted order of the index:\n",
    "- if the index is sorted ascending (earliest date first) then the slice will be: **df['early_date' : 'late_date']**\n",
    "- if the index is sorted descending (earliest date last) then the slice will be: **df['late_date' : 'early_date']**\n",
    "- If your index and slice order aren't the same then an empty DataFrame will be returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# make sure the dates are ascending (earliest date first)\n",
    "df_GOOGL = df_GOOGL.sort_index(ascending=True)\n",
    "\n",
    "# slice between specific dates\n",
    "df_GOOGL['2010-12-02':'2010-12-25']\n",
    "\n",
    "# In steps of 30 calendar days\n",
    "df_GOOGL['2010-12':'2012-1':30]\n",
    "\n",
    "# between months in steps of 45 days\n",
    "df_GOOGL['2010-Nov':'2011-MAY':45]\n",
    "\n",
    "# use variables\n",
    "start = datetime(2015, 11, 2)\n",
    "stop = datetime(2015,12,23)\n",
    "\n",
    "df_GOOGL[start:stop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date Ranges and Frequencies\n",
    "\n",
    "- Extremely useful in the field of finance\n",
    "- Convenient syntax\n",
    "- version 1 - start, stop, frequency\n",
    "- version 2 - start, frequency, periods\n",
    "\n",
    "- full list of date frequencies here - http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.date_range(start='2010-01-01', end='2015-12-31', freq='Q')\n",
    "pd.date_range(start='2010-01-01', end='2015-12-31', freq='Q-JAN')\n",
    "\n",
    "# Note that there are special 'business rules' for some dates, e.g. WOM-3FRI\n",
    "# The pandas lbrary designers put anchors etc. into some of their frequency accessors:\n",
    "# http://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#anchored-offsets\n",
    "pd.date_range(start='2010-01-01', end='2015-12-31', freq='WOM-3FRI')\n",
    "\n",
    "# There are also some convenient syntax\n",
    "pd.date_range(start='2010-01-01', end='2010-03-01', freq='4H')\n",
    "pd.date_range(start='2010-01-01', periods=10, freq='1h30min')\n",
    "\n",
    "# Use a Start, Frequene and periods for other variations\n",
    "pd.date_range(start='2010-01-01', freq='WOM-3FRI', periods=5)\n",
    "\n",
    "# Using the data range to look up data\n",
    "days_of_month = pd.date_range(start='2010', end='2011', freq='BM')\n",
    "\n",
    "# using loc - will be deprecated soon and return an error\n",
    "df_GOOGL.loc[days_of_month]\n",
    "\n",
    "# prefer the reindex method instead\n",
    "df_GOOGL.reindex(labels = days_of_month)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting\n",
    "\n",
    "Sliding data along a timeseries index\n",
    "\n",
    "- Shift forward - the most recent are lost - Nan\n",
    "\n",
    "- Shift backwards - the least recent are lost - Nan\n",
    "\n",
    "Use shift and tshift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.shift(1).head()\n",
    "df_GOOGL.shift(1).tail()\n",
    "\n",
    "df_GOOGL.shift(-1).head()\n",
    "df_GOOGL.shift(-1).tail()\n",
    "\n",
    "# Shift everything forward 30 days - use a t-shift for this\n",
    "df_GOOGL.tshift(periods=30, freq='D').head(40)\n",
    "\n",
    "# 2 months\n",
    "df_GOOGL.tshift(periods=2, freq='M')\n",
    "\n",
    "# 3 years\n",
    "df_GOOGL.tshift(periods=3, freq='Y').tail(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling\n",
    "\n",
    "Resampling is a conversion between frequencies\n",
    "\n",
    "- **Downsampling** - the easiest - going from a finer grained frequency to a lower grained frequency. e.g. Days to Months, Months to Years\n",
    "- **Upsampling** - slightly more involved - the reverse, e.g. months to days, days to minutes\n",
    "\n",
    "Upsampling will require some interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_GOOGL.resample(rule='Y').mean()\n",
    "\n",
    "# Downsample = aggregating to a lower frequency\n",
    "# e.g. - single mins to 5mins, 15mins to hours, days to weeks etc\n",
    "# Downsample from days to months\n",
    "df_MON = df_GOOGL['2010'].resample(rule = 'M').mean()\n",
    "df_MON\n",
    "\n",
    "# Upsample = from Months to Weeks\n",
    "# aggregating to a higher frequency\n",
    "df_MON.resample(rule='W').mean()\n",
    "\n",
    "# use ffill or bfill to fill forwards or backwards when upsampling\n",
    "df_MON.resample(rule='W').ffill()\n",
    "df_MON.resample(rule='W').bfill()\n",
    "\n",
    "# use limit to limit the forward or backward fills\n",
    "df_MON.resample(rule='W').ffill(limit=2)\n",
    "df_MON.resample(rule='W').bfill(limit=2)\n",
    "\n",
    "\n",
    "# Interpolate\n",
    "# default is linear\n",
    "df_MON.resample(rule='D').interpolate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some different interpolations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame()\n",
    "\n",
    "df_tmp['Cubic'] = df_MON['Open'].resample(rule='D').interpolate(method='cubic')\n",
    "df_tmp['Linear'] = df_MON['Open'].resample(rule='D').interpolate(method='linear')\n",
    "df_tmp['Quadratic']  = df_MON['Open'].resample(rule='D').interpolate(method='quadratic')\n",
    "\n",
    "df_tmp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moving Windows\n",
    "\n",
    "- `rolling()` - create a window and slide along, returning a Series as you go\n",
    "- `expanding()` - gradually increase the size of your window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A rolling 252 day mean for business days\n",
    "df_Close = df_GOOGL['Close'].resample('D').ffill()\n",
    "df_Close.plot()\n",
    "df_Close.rolling(252).mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can set a minimum number of periods to shorten the number of invalid data points\n",
    "df_Close.head()\n",
    "df_Close.rolling(250).mean().head()\n",
    "df_Close.rolling(250, min_periods=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanding\n",
    "df_Close.plot()\n",
    "df_Close.rolling(250, min_periods=3).mean().plot()\n",
    "df_Close.expanding().mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Data\n",
    "\n",
    "- Quite often you will want to resample and apply a function to the aggregate\n",
    "- You have already done this, e.g. **df.resample(rule='BQ').mean()**\n",
    "- A more convenient way is to use the `agg()` method and supply it with the name of the function you want to apply to your aggregate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One way\n",
    "df_Close.resample(rule='Y').mean()\n",
    "\n",
    "# Use the agg function\n",
    "df_Close.resample(rule='Y').agg('mean') \n",
    "\n",
    "# Create a variable to store the name of the function\n",
    "func = 'mean'\n",
    "df_Close.resample(rule='Y').agg(func)\n",
    "\n",
    "# Create a list of functions to aggregate with\n",
    "funcs = ['mean', 'max', 'min']\n",
    "df_Close.resample(rule='Y').agg(funcs)\n",
    "\n",
    "#  Try this for IBM\n",
    "funcs = ['mean', 'max', 'min']\n",
    "df_GOOGL.resample(rule='Y').agg(funcs)\n",
    "\n",
    "# Be a little more selective on which columns to aggregate\n",
    "cols = ['Open', 'High', 'Low', 'Close']\n",
    "df_GOOGL[cols].resample(rule='Y').agg(funcs)\n",
    "\n",
    "# And now only for 2016 to 2017 but for Business Quarter\n",
    "df_GOOGL['2016':'2017'][cols].resample(rule='BQ').agg(funcs)\n",
    "\n",
    "\n",
    "# Same as above but transposed \n",
    "df_GOOGL['2016':'2017'][cols].resample(rule='BQ').agg(funcs).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
